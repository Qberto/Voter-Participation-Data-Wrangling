{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Engineering](img/header2.JPG \"Data Engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: darkblue\">Voter Turnout in Presidential Elections</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this notebook and project to explore, visualize, and analyze presidential election participation data, otherwise known as \"voter turnout\". Elections are voluntary in the United States and understanding the spatial characteristics of voter turnout is very important to understand how policy decisions are made based on who participated in the election process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin with <span style=\"color:purple\">Data Engineering</span>: Broadly described as the actions taken to make data useful for analysis. Whether itâ€™s removing records with erroneous data, reformatting the structure of a table to better conduct analysis, or several other actions that may help you prepare data, Data Engineering is an important part of every analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by downloading and preparing US presidential election [data from MIT's Election Data and Science Lab](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ), including handling missing values, reformatting data types, and restructuring the format of a table. Using GIS, Data Engineering can then make use of geocoding and geoenrichment to further prepare our data for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Step 1: Load and Clean Election Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Goals:\n",
    "- Handle missing values\n",
    "- Correct truncated zeroes with FIPS field\n",
    "- Restructure table format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To download and prepare the election data available, we will use a mix of Pandas, ArcPy, and the ArcGIS API for Python. Dataframes in Pandas serve as an effective way to format data and fix issues. First, let's import the necessary modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Import needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The import statements load each module\n",
    "import arcgis\n",
    "import pandas as pd\n",
    "import os\n",
    "import arcpy  # Best practice: Load arcpy last to maintain priority for namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Read data into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make reference to the file path for the csv, which should be in the same directory as the notebook\n",
    "table_csv_path = \"countypres_2000-2016.csv\"\n",
    "\n",
    "# Use Pandas to read the csv into a dataframe\n",
    "data_df = pd.read_csv(table_csv_path, dtype={'year': str, 'FIPS': str})  # dtype parameter specifies that year and FIPS fields are string\n",
    "\n",
    "# Use the head function to display the first five records of the dataframe\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Handle missing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![Null Values](img/null_values.gif \"Null Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set the field to check nulls for\n",
    "field_to_check = \"FIPS\"\n",
    "\n",
    "# Determine how many rows are in the table\n",
    "rowcount = data_df.shape[0]\n",
    "\n",
    "# Determine how many rows have null FIPS \n",
    "null_fips_rowcount = data_df.loc[data_df[field_to_check].isnull()].shape[0]\n",
    "\n",
    "# Calculate how much of the data this represents as a percentage\n",
    "percentage_null_fips = round((null_fips_rowcount / rowcount) * 100, 2)\n",
    "\n",
    "# Use a print statement to report this information\n",
    "print(\"There were \"+str(null_fips_rowcount)+\" records with null \"+str(field_to_check)+\" values in the data.\\nThis amounts to \" +str(percentage_null_fips)+\"% of the available data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use the notnull function and the loc function to create a new dataframe without null FIPS records\n",
    "data_df = data_df.loc[data_df['FIPS'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Explore and handle data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![fix_truncated_zeroes](img/trunc_zeroes.gif \"Fix Truncated Zeroes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get the first five records of the table\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check how many records have a FIPS value with four characters\n",
    "trunc_df = data_df.loc[data_df['FIPS'].str.len() == 4]\n",
    "trunc_data_per = (trunc_df.shape[0] / data_df.shape[0])*100\n",
    "\n",
    "# Use another print statement (using the f format key) to report this information\n",
    "print(f\"{round(trunc_data_per, 2)}% of data ({trunc_df.shape[0]} rows) has truncated FIPS values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next, we need to fix the FIPS field since the data has leading zeroes truncated by its interpretation as a numeric field. We can create a simple function in python to determine if the value is four characters, and append a leading zero if that's the case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define a helper function to fix truncated zeros, with one parameter: the value to be processed\n",
    "def fix_trunc_zeros(val):\n",
    "    # Use an if statement to check if there are four characters in the string representation of the value\n",
    "    if len(str(val)) == 4:\n",
    "        # If this is the case, return the value with an appended \"0\" in the front\n",
    "        return \"0\"+str(val)\n",
    "    # Otherwise...\n",
    "    else:\n",
    "        # Return the value itself\n",
    "        return str(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test helper function with truncated value\n",
    "fix_trunc_zeros(7042)  # You should see an appended zero: \"07042\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run helper function on the FIPS field using the apply and lambda method \n",
    "data_df['FIPS'] = data_df['FIPS'].apply(lambda x: fix_trunc_zeros(x))\n",
    "\n",
    "# Print information on the operation performed, and show the first few records to confirm it worked\n",
    "print(f\"{round(trunc_data_per, 2)}% of data ({trunc_df.shape[0]} rows) had truncated FIPS IDs corrected.\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Reformat the table structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![reformat_table](img/reformat_table.gif \"Reformat Table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We now need to reformat the structure of the table. Currently, each record corresponds to a candidate and their votes in a particular county. We need each record to correspond to each county, with fields showing the votes for different candidates for that election year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The animation above displays the reformatting necessary. It is possible to do this using Excel pivot tables, but a Python script to perform this might make things a bit easier to automate and share. The following code cell performs all the actions displayed above in the animation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reformat the dataframe by setting a multiindex (set_index with multiple fields) and pivoting the table (unstack)\n",
    "df_out = data_df.set_index(['FIPS', \n",
    "                            'year', \n",
    "                            'county', \n",
    "                            'state', \n",
    "                            'state_po', \n",
    "                            'office', \n",
    "                            data_df.groupby(['FIPS', 'year']).cumcount()+1]).unstack()\n",
    "\n",
    "# Use the indexes for the columns to set column names (Ex: candidate_1, candidate_2, votes_1, votes_2, etc.)\n",
    "df_out.columns = df_out.columns.map('{0[0]}_{0[1]}'.format)\n",
    "\n",
    "# Rename columns \n",
    "df_out = df_out.rename(columns={\"candidate_1\": \"candidate_dem\",\n",
    "                                \"candidatevotes_1\": \"votes_dem\",\n",
    "                                \"candidate_2\": \"candidate_gop\",\n",
    "                                \"candidatevotes_2\": \"votes_gop\",\n",
    "                                \"totalvotes_1\": \"votes_total\",\n",
    "                                \"state_po\": \"state_abbrev\"\n",
    "                                })\n",
    "\n",
    "# Keep only the necessary columns\n",
    "df_out = df_out[[\"candidate_dem\", \"votes_dem\",\n",
    "                 \"candidate_gop\", \"votes_gop\",\n",
    "                 \"votes_total\"]]\n",
    "\n",
    "# Remove the multiindex since we no longer need these fields to be \"locked\" for the pivot\n",
    "df_out.reset_index(inplace=True)\n",
    "\n",
    "# Print out the first few records to confirm everything worked\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Let's break this down step by step and fully understand it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First, take a few seconds to rewatch the animation above again and consider each step. \n",
    "\n",
    "In essence, we need to:\n",
    "\n",
    "1. Set a few fields aside, \"locking\" them from the table pivot. \n",
    "2. Pivot the table using the remaining fields.\n",
    "3. Give the pivoted fields designations for each party. \n",
    "4. Bring the locked fields back to our table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For context, Pandas has the following powerful capabilities that help us perform this operation: \n",
    "\n",
    "- The ability to set an index using multiple fields, which acts as our \"locking\" mechanism for step 1. \n",
    "- The ability to perform an operation using a \"groupby\" function, which lets us group each observation by candidate/party\n",
    "- The ability to unstack a table, which lets us handle the table pivot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1. Setting an index using multiple fields** allows us to designate specific fields as index fields, which will not be impacted when a table pivot occurs. In other words, the fields specified in the set_index part of code above are \"locked\" when the later part of the code performs the table pivot via the \"unstack\" function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Notice how running this cell uses the specified fields as row indices, \n",
    "# which prevents them from being \"rotated\" in the table pivot\n",
    "data_df.set_index(['FIPS', \n",
    "                   'year', \n",
    "                   'county', \n",
    "                   'state', \n",
    "                   'state_po', \n",
    "                   'office'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**2. The built-in groupby function** allows us to perform an operation using the unique values from a specified set of fields. This is useful because we can then count how many rows exist for a given FIPS and Year combination, which essentially lets us group data by the candidate that it pertains to. See the following example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_df.set_index(['FIPS', \n",
    "                   'year', \n",
    "                   'county', \n",
    "                   'state', \n",
    "                   'state_po', \n",
    "                   'office', \n",
    "                   data_df.groupby(['FIPS', 'year']).cumcount()+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**3. The ability to unstack a table** allows us to perform the table pivot, which essentially \"rotates\" the table and makes rows into columns (or columns into rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_df.set_index(['FIPS', \n",
    "                   'year', \n",
    "                   'county', \n",
    "                   'state', \n",
    "                   'state_po', \n",
    "                   'office', \n",
    "                   data_df.groupby(['FIPS', 'year']).cumcount()+1]).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**4. Finally, we put it all together and rename the output columns**, using the pandas ability to rename fields and removing extraneous fields we no longer need. This produces the table format we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Reformat the dataframe by setting a multiindex (set_index with multiple fields) and pivoting the table (unstack)\n",
    "df_out = data_df.set_index(['FIPS', \n",
    "                            'year', \n",
    "                            'county', \n",
    "                            'state', \n",
    "                            'state_po', \n",
    "                            'office', \n",
    "                            data_df.groupby(['FIPS', 'year']).cumcount()+1]).unstack()\n",
    "\n",
    "# Use the indexes for the columns to set column names (Ex: candidate_1, candidate_2, votes_1, votes_2, etc.)\n",
    "df_out.columns = df_out.columns.map('{0[0]}_{0[1]}'.format)\n",
    "\n",
    "# Rename columns \n",
    "df_out = df_out.rename(columns={\"candidate_1\": \"candidate_dem\",\n",
    "                                \"candidatevotes_1\": \"votes_dem\",\n",
    "                                \"candidate_2\": \"candidate_gop\",\n",
    "                                \"candidatevotes_2\": \"votes_gop\",\n",
    "                                \"totalvotes_1\": \"votes_total\",\n",
    "                                \"state_po\": \"state_abbrev\"\n",
    "                                })\n",
    "\n",
    "# Keep only the necessary columns\n",
    "df_out = df_out[[\"candidate_dem\", \"votes_dem\",\n",
    "                 \"candidate_gop\", \"votes_gop\",\n",
    "                 \"votes_total\"]]\n",
    "\n",
    "# Remove the multiindex since we no longer need these fields to be \"locked\" for the pivot\n",
    "df_out.reset_index(inplace=True)\n",
    "\n",
    "# Print out the first few records to confirm everything worked\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Calculate Additional Columns/Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Calculate total votes for non major party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate votes that did not go for the Democrat or Republican party\n",
    "df_out['votes_other'] = df_out['votes_total'] - (df_out['votes_dem'] + df_out['votes_gop'])\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Create additional attributes (voter percentages and raw differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate voter share attributes\n",
    "df_out['voter_share_major_party'] = (df_out['votes_dem'] + df_out['votes_gop']) / df_out['votes_total']\n",
    "df_out['voter_share_dem'] = df_out['votes_dem'] / df_out['votes_total']\n",
    "df_out['voter_share_gop'] = df_out['votes_gop'] / df_out['votes_total']\n",
    "df_out['voter_share_other'] = df_out['votes_other'] / df_out['votes_total']\n",
    "\n",
    "# Calculate raw difference attributes\n",
    "df_out['rawdiff_dem_vs_gop'] = df_out['votes_dem'] - df_out['votes_gop']\n",
    "df_out['rawdiff_gop_vs_dem'] = df_out['votes_gop'] - df_out['votes_dem']\n",
    "df_out['rawdiff_dem_vs_other'] = df_out['votes_dem'] - df_out['votes_other']\n",
    "df_out['rawdiff_gop_vs_other'] = df_out['votes_gop'] - df_out['votes_other']\n",
    "df_out['rawdiff_other_vs_dem'] = df_out['votes_other'] - df_out['votes_dem']\n",
    "df_out['rawdiff_other_vs_gop'] = df_out['votes_other'] - df_out['votes_gop']\n",
    "\n",
    "# Calculate percent difference attributes\n",
    "df_out['pctdiff_dem_vs_gop'] = (df_out['votes_dem'] - df_out['votes_gop']) / df_out['votes_total']\n",
    "df_out['pctdiff_gop_vs_dem'] = (df_out['votes_gop'] - df_out['votes_dem']) / df_out['votes_total']\n",
    "df_out['pctdiff_dem_vs_other'] = (df_out['votes_dem'] - df_out['votes_other']) / df_out['votes_total']\n",
    "df_out['pctdiff_gop_vs_other'] = (df_out['votes_gop'] - df_out['votes_other']) / df_out['votes_total']\n",
    "df_out['pctdiff_other_vs_dem'] = (df_out['votes_other'] - df_out['votes_dem']) / df_out['votes_total']\n",
    "df_out['pctdiff_other_vs_gop'] = (df_out['votes_other'] - df_out['votes_gop']) / df_out['votes_total']\n",
    "\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Step 2: Geoenable election data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Goals:\n",
    "   - Retrieve 2016 USA county population GIS data\n",
    "   - Perform join, bringing geometry to election data\n",
    "   - Calculate Voter Turnout per county\n",
    "   - Convert dataframe to feature class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will now bring geometry data for each county into the table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Retrieve 2016 USA county population GIS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A useful source of data is the [ArcGIS Living Atlas of the World](https://livingatlas.arcgis.com), where we can find a service containing [Voting Age Population totals (citizens aged 18+) for each county](https://www.arcgis.com/home/item.html?id=2e8aaf91178c4c91b974d0bc4234dbfa). \n",
    "\n",
    "This dataset is included with this project to allow you to append the election data to county geometry and allow us to calculate voting turnout for each county. The next few cells will load this feature class into a spatially-enabled dataframe and allow us to geoenable the election data we have been preparing. Additionally, this feature class allows us to actually calculate voter turnout since it includes voting-age population counts for 2016. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will now reference this ArcGIS Pro project and its file geodatabase using ArcPy as well. Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Authenticate with a GIS using the ArcGIS API for Python\n",
    "gis = arcgis.gis.GIS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Search for USA_Counties\n",
    "search = gis.content.search(\"USA Counties\", item_type=\"feature_service\", outside_org=True, sort_field=\"numViews\")\n",
    "# Use the correct index to reference the search result\n",
    "counties_item = search[2]\n",
    "counties_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read the layer into a dataframe\n",
    "counties_df = pd.DataFrame.spatial.from_layer(counties_item.layers[0])\n",
    "counties_df = counties_df[['FIPS', 'NAME', 'STATE_FIPS', 'STATE_NAME', 'OBJECTID', 'POPULATION', 'POP_SQMI', 'SHAPE', 'Shape_Area', 'Shape_Leng', 'Shape__Area', 'Shape__Length']]\n",
    "counties_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Perform join, bringing geometry and population column to election data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We now have a dataframe with election data ('df_out') and a spatially-enabled dataframe of county voting-age population data ('counties_df'). Let's merge the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Join the data to our election data table\n",
    "geo_df = pd.merge(df_out, counties_df, left_on='FIPS', right_on=\"FIPS\", how='left')\n",
    "# Visualize the merged data, notice the SHAPE column at the end\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a copy of the data, and perform a query\n",
    "data_2016_df = geo_df.copy()\n",
    "data_2016_df.query(\"year == '2016'\", inplace=True)\n",
    "data_2016_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Convert dataframe to feature class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can now finally convert our data to feature classes! The ArcGIS API for Python (which was invoked by using \"import arcgis\") lets us export the spatially-enabled dataframe to a feature class so we can do further analysis.\n",
    "\n",
    "**Note: Executing the following cell may take a few minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a subset of the data just for the 2016 presidential election\n",
    "fgdb = r\"C:\\Users\\albe9057\\Documents\\ArcGIS\\Projects\\Data Engineering and Visualization\\Data Engineering and Visualization.gdb\"\n",
    "out_2016_fc_name = \"county_elections_pres_2016\"\n",
    "out_2016_fc = data_2016_df.spatial.to_featureclass(os.path.join(fgdb, out_2016_fc_name))\n",
    "out_2016_fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Select the Map tab (titled \"Data Engineering\"), and view the added layers to the Table of Contents. You will now see counties across the United States with 2016 voting turnout data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Step 3: Geoenrich election data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Goals:\n",
    "   - Use Geoenrichment to bring demographic and socioeconomic variables to use in analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Geoenrichment in ArcGIS Pro allows us to add columns of data for each county that can help us analyze relationships and potentially model voter turnout. Geoenrichment can be performed using ArcPy, but we recommend that you use the GeoProcessing Enrich tool to explore potential variables that may help explain voter turnout. You may now reference the MOOC guidance for the steps covering how to geoenrich this data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
